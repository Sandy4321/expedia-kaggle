{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "destinations = pd.read_csv(\"destinations.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"date_time\"] = pd.to_datetime(train[\"date_time\"])\n",
    "train[\"year\"] = train[\"date_time\"].dt.year\n",
    "train[\"month\"] = train[\"date_time\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unique_users = train.user_id.unique()\n",
    "\n",
    "sel_user_ids = [unique_users[i] for i in sorted(random.sample(range(len(unique_users)), 10000)) ]\n",
    "sel_train = train[train.user_id.isin(sel_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = sel_train[((sel_train.year == 2013) | ((sel_train.year == 2014) & (sel_train.month < 8)))]\n",
    "t2 = sel_train[((sel_train.year == 2014) & (sel_train.month >= 8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2 = t2[t2.is_booking == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_common_clusters = list(train.hotel_cluster.value_counts().head().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [most_common_clusters for i in range(t2.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ml_metrics as metrics\n",
    "target = [[l] for l in t2[\"hotel_cluster\"]]\n",
    "metrics.mapk(target, predictions, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.corr()['hotel_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "dest_small = pca.fit_transform(destinations[[\"d{0}\".format(i + 1) for i in range(149)]])\n",
    "dest_small = pd.DataFrame(dest_small)\n",
    "dest_small[\"srch_destination_id\"] = destinations[\"srch_destination_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_fast_features(df):\n",
    "    df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    df[\"srch_ci\"] = pd.to_datetime(df[\"srch_ci\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    df[\"srch_co\"] = pd.to_datetime(df[\"srch_co\"], format='%Y-%m-%d', errors=\"coerce\")\n",
    "    \n",
    "    props = {}\n",
    "    for prop in [\"month\", \"day\", \"hour\", \"minute\", \"dayofweek\", \"quarter\"]:\n",
    "        props[prop] = getattr(df[\"date_time\"].dt, prop)\n",
    "    \n",
    "    carryover = [p for p in df.columns if p not in [\"date_time\", \"srch_ci\", \"srch_co\"]]\n",
    "    for prop in carryover:\n",
    "        props[prop] = df[prop]\n",
    "    \n",
    "    date_props = [\"month\", \"day\", \"dayofweek\", \"quarter\"]\n",
    "    for prop in date_props:\n",
    "        props[\"ci_{0}\".format(prop)] = getattr(df[\"srch_ci\"].dt, prop)\n",
    "        props[\"co_{0}\".format(prop)] = getattr(df[\"srch_co\"].dt, prop)\n",
    "    props[\"stay_span\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).astype('timedelta64[h]')\n",
    "        \n",
    "    ret = pd.DataFrame(props)\n",
    "    \n",
    "    ret = ret.join(dest_small, on=\"srch_destination_id\", how='left', rsuffix=\"dest\")\n",
    "    ret = ret.drop(\"srch_destination_iddest\", axis=1)\n",
    "    return ret\n",
    "\n",
    "df = calc_fast_features(t1)\n",
    "df.fillna(-1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [c for c in df.columns if c not in [\"hotel_cluster\"]]\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)\n",
    "scores = cross_validation.cross_val_score(clf, df[predictors], df['hotel_cluster'], cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from itertools import chain\n",
    "\n",
    "all_probs = []\n",
    "unique_clusters = df[\"hotel_cluster\"].unique()\n",
    "for cluster in unique_clusters:\n",
    "    df[\"target\"] = 1\n",
    "    df[\"target\"][df[\"hotel_cluster\"] != cluster] = 0\n",
    "    predictors = [col for col in df if col not in ['hotel_cluster', \"target\"]]\n",
    "    probs = []\n",
    "    cv = KFold(len(df[\"target\"]), n_folds=2)\n",
    "    clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)\n",
    "    for i, (tr, te) in enumerate(cv):\n",
    "        clf.fit(df[predictors].iloc[tr], df[\"target\"].iloc[tr])\n",
    "        preds = clf.predict_proba(df[predictors].iloc[te])\n",
    "        probs.append([p[1] for p in preds])\n",
    "    full_probs = chain.from_iterable(probs)\n",
    "    all_probs.append(list(full_probs))\n",
    "\n",
    "prediction_frame = pd.DataFrame(all_probs).T\n",
    "prediction_frame.columns = unique_clusters\n",
    "def find_top_5(row):\n",
    "    return list(row.nlargest(5).index)\n",
    "\n",
    "preds = []\n",
    "for index, row in prediction_frame.iterrows():\n",
    "    preds.append(find_top_5(row))\n",
    "\n",
    "metrics.mapk([[l] for l in t2.iloc[\"hotel_cluster\"]], preds, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_key(items):\n",
    "    return \"_\".join([str(i) for i in items])\n",
    "\n",
    "match_cols = [\"srch_destination_id\"]\n",
    "cluster_cols = match_cols + ['hotel_cluster']\n",
    "groups = t1.groupby(cluster_cols)\n",
    "top_clusters = {}\n",
    "for name, group in groups:\n",
    "    clicks = len(group.is_booking[group.is_booking == False])\n",
    "    bookings = len(group.is_booking[group.is_booking == True])\n",
    "    \n",
    "    score = bookings + .15 * clicks\n",
    "    \n",
    "    clus_name = make_key(name[:len(match_cols)])\n",
    "    if clus_name not in top_clusters:\n",
    "        top_clusters[clus_name] = {}\n",
    "    top_clusters[clus_name][name[-1]] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "cluster_dict = {}\n",
    "for n in top_clusters:\n",
    "    tc = top_clusters[n]\n",
    "    top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]]\n",
    "    cluster_dict[n] = top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for index, row in t2.iterrows():\n",
    "    key = make_key([row[m] for m in match_cols])\n",
    "    if key in cluster_dict:\n",
    "        preds.append(cluster_dict[key])\n",
    "    else:\n",
    "        preds.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], preds, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Performing matching between test and train data. To exploit the leak\n",
    "\n",
    "match_cols = ['user_location_country', 'user_location_region', 'user_location_city', 'hotel_market', 'orig_destination_distance']\n",
    "\n",
    "groups = t1.groupby(match_cols)\n",
    "    \n",
    "def generate_exact_matches(row, match_cols):\n",
    "    index = tuple([row[t] for t in match_cols])\n",
    "    try:\n",
    "        group = groups.get_group(index)\n",
    "    except Exception:\n",
    "        return []\n",
    "    clus = list(set(group.hotel_cluster))\n",
    "    return clus\n",
    "\n",
    "exact_matches = []\n",
    "for i in range(t2.shape[0]):\n",
    "    exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Combining  1. Exact matches 2. Predictions 3. Most common clusters. \n",
    "\n",
    "def f5(seq, idfun=None): \n",
    "    if idfun is None:\n",
    "        def idfun(x): return x\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen: continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result\n",
    "    \n",
    "full_preds = [f5(exact_matches[p] + preds[p] + most_common_clusters)[:5] for p in range(len(preds))]\n",
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], full_preds, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Complete algorithm\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "t1 = train\n",
    "t2 = test\n",
    "\n",
    "\n",
    "def make_key(items):\n",
    "    return \"_\".join([str(i) for i in items])\n",
    "\n",
    "match_cols = [\"srch_destination_id\"]\n",
    "cluster_cols = match_cols + ['hotel_cluster']\n",
    "groups = t1.groupby(cluster_cols)\n",
    "top_clusters = {}\n",
    "for name, group in groups:\n",
    "    clicks = len(group.is_booking[group.is_booking == False])\n",
    "    bookings = len(group.is_booking[group.is_booking == True])\n",
    "    \n",
    "    score = bookings + .15 * clicks\n",
    "    \n",
    "    clus_name = make_key(name[:len(match_cols)])\n",
    "    if clus_name not in top_clusters:\n",
    "        top_clusters[clus_name] = {}\n",
    "    top_clusters[clus_name][name[-1]] = score\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "import operator\n",
    "\n",
    "cluster_dict = {}\n",
    "for n in top_clusters:\n",
    "    tc = top_clusters[n]\n",
    "    top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]]\n",
    "    cluster_dict[n] = top\n",
    "    \n",
    "    \n",
    "preds = []\n",
    "for index, row in t2.iterrows():\n",
    "    key = make_key([row[m] for m in match_cols])\n",
    "    if key in cluster_dict:\n",
    "        preds.append(cluster_dict[key])\n",
    "    else:\n",
    "        preds.append([])\n",
    "\n",
    "        \n",
    "#t2 does not have hotel_cluster. We used this line for our mapk score.\n",
    "# metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], preds, k=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##Performing matching between test and train data. To exploit the leak\n",
    "\n",
    "match_cols = ['user_location_country', 'user_location_region', 'user_location_city', 'hotel_market', 'orig_destination_distance']\n",
    "\n",
    "groups = t1.groupby(match_cols)\n",
    "    \n",
    "def generate_exact_matches(row, match_cols):\n",
    "    index = tuple([row[t] for t in match_cols])\n",
    "    try:\n",
    "        group = groups.get_group(index)\n",
    "    except Exception:\n",
    "        return []\n",
    "    clus = list(set(group.hotel_cluster))\n",
    "    return clus\n",
    "\n",
    "exact_matches = []\n",
    "for i in range(t2.shape[0]):\n",
    "    exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "##Combining  1. Exact matches 2. Predictions 3. Most common clusters. \n",
    "\n",
    "def f5(seq, idfun=None): \n",
    "    if idfun is None:\n",
    "        def idfun(x): return x\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen: continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result\n",
    "    \n",
    "full_preds = [f5(exact_matches[p] + preds[p] + most_common_clusters)[:5] for p in range(len(preds))]\n",
    "\n",
    "write_p = [\" \".join([str(l) for l in p]) for p in full_preds]\n",
    "write_frame = [\"{0},{1}\".format(t2[\"id\"][i], write_p[i]) for i in range(len(full_preds))]\n",
    "write_frame = [\"id,hotel_clusters\"] + write_frame\n",
    "with open(\"predictions.csv\", \"w+\") as f:\n",
    "    f.write(\"\\n\".join(write_frame))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
